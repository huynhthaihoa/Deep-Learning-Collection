








<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Jupyter Notebook Viewer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">
  
  <meta name="robots" content="noindex,nofollow">
  

  <!--NEW RELIC Start Perf Measurement-->
  
  <!--NREND-->

  <!-- Le styles -->
  <link href="/static/build/styles.css" rel="stylesheet">

  <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <!-- Le fav and touch icons -->
  <link rel="shortcut icon" href="/static/ico/ipynb_icon_16x16.png">
  <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="/static/ico/apple-touch-icon-144-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="114x114"
        href="/static/ico/apple-touch-icon-114-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="72x72"
        href="/static/ico/apple-touch-icon-72-precomposed.png">
  <link rel="apple-touch-icon-precomposed"
        href="/static/ico/apple-touch-icon-57-precomposed.png">
  
  

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Notebook on nbviewer">
  <meta name="twitter:description" content="Check out this Jupyter notebook!">

  
  <meta name="twitter:domain" content="nbviewer.jupyter.org">
  <meta name="twitter:image:src" content="http://ipython.org/ipython-doc/dev/_images/ipynb_icon_128x128.png">

  
    <link href="/static/build/notebook.css" rel="stylesheet">
  

  

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
    <script type="text/javascript">
      init_mathjax = function() {
        if (window.MathJax) {
          // MathJax loaded
          MathJax.Hub.Config({
            TeX: {
              equationNumbers: {
                autoNumber: "AMS",
                useLabelIds: true
              }
            },
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
            },
            displayAlign: 'center',
            "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
            }
          });
          MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
      }
      init_mathjax();
    </script>
  

  
    <script>
      (function() {
        function addWidgetsRenderer() {
          var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
          var scriptElement = document.createElement('script');
          var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@0.15/dist/embed-amd.js';
          var widgetState;

          try {
            widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

            if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
              widgetRendererSrc = 'https://unpkg.com/jupyter-js-widgets@2.1/dist/embed.js';
            }
          } catch(e) {}

          scriptElement.src = widgetRendererSrc;
          document.body.appendChild(scriptElement);
        }

        document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
      }());
    </script>
  

</head>

<body class="nbviewer">

  <!-- These are loaded at the top of the body so they are available to
       notebook cells when they are loaded below. -->
  <script src="/static/components/jquery/dist/jquery.min.js"></script>
  <script src="/static/components/requirejs/require.js"></script>
  <script src="/static/components/moment/min/moment.min.js"></script>
<!-- Navbar
================================================== -->
  <nav id="menubar" class="navbar navbar-default navbar-fixed-top" data-spy="affix">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand" href="/">
          <img src="/static/img/nav_logo.svg" width="159"/>
        </a>
      </div>

      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a class="active" href="https://jupyter.org">JUPYTER</a>
          </li>
          <li>
    <a href="/faq" title="FAQ" >
      
        <span>FAQ</span>
      
    </a>
  </li>

          
  
    
  
    
      
        <li>
    <a href="script/url/www.cs.toronto.edu/~rgrosse/courses/csc321_2018/tutorials/tut8_complete.ipynb" title="View as Code" >
      <span class="fa fa-code fa-2x menu-icon"></span>
      <span class="menu-text">View as Code</span>
    </a>
  </li>
      
    
  

  
    <li>
    <a href="#" title="Python [default] Kernel" >
      <span class="fa fa-server fa-2x menu-icon"></span>
      <span class="menu-text">Python [default] Kernel</span>
    </a>
  </li>
  

  

  

  <li>
    <a href="http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/tutorials/tut8_complete.ipynb" title="Download Notebook" download>
      <span class="fa fa-download fa-2x menu-icon"></span>
      <span class="menu-text">Download Notebook</span>
    </a>
  </li>

        </ul>
      </div><!-- /.navbar-collapse -->
      
      
    </div>
  </nav>

  <div class="container container-main">
    
  
  <div id="notebook">
    <div id="notebook-container">
      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introducing-RNNs-and-LSTMs">Introducing RNNs and LSTMs<a class="anchor-link" href="#Introducing-RNNs-and-LSTMs">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">autograd</span>
<span class="kn">import</span> <span class="nn">autograd.optimizers</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">autograd</span> <span class="kn">import</span> <span class="n">grad</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Resources">Resources<a class="anchor-link" href="#Resources">&#182;</a></h2><p>You may find the following resources helpful for understanding how RNNs and LSTMs work:</p>
<ul>
<li><a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of RNNs (Andrej Karpathy)</a></li>
<li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">Recurrent Neural Networks Tutorial (Wild ML)</a></li>
<li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks (Chris Olah)</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Character-Level-Language-Model">Character-Level Language Model<a class="anchor-link" href="#Character-Level-Language-Model">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Load the Shakespeare text</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/shakespeare.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------&quot;</span><span class="p">)</span>
<span class="c1"># Print a sample of the text</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="n">data_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>   <span class="c1"># + 1      # The extra + 1 is for the end-of-string token</span>

<span class="n">char_to_index</span> <span class="o">=</span> <span class="p">{</span> <span class="n">char</span><span class="p">:</span><span class="n">index</span> <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span><span class="n">char</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span> <span class="p">}</span>
<span class="n">index_to_char</span> <span class="o">=</span> <span class="p">{</span> <span class="n">index</span><span class="p">:</span><span class="n">char</span> <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span><span class="n">char</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span> <span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TOTAL NUM CHARACTERS = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_length</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NUM UNIQUE CHARACTERS = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------------------
First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You
------------------------------
TOTAL NUM CHARACTERS = 1115394
NUM UNIQUE CHARACTERS = 65
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="RNN">RNN<a class="anchor-link" href="#RNN">&#182;</a></h2><p><img src="images/rnn.jpg" alt="Recurrent Neural Network Diagram">
(Image from the <a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">Wild ML RNN Tutorial</a>)</p>
<p>The update of an RNN is expressed by the following formulas:</p>
$$
h_t = \tanh(U x_t + W h_{t-1} + b_h)
$$$$
y_t = \text{softmax}(V h_t + b_y)
$$<p>Here, each $x_t$ is a <em>character</em>---in this example, there are 65 unique characters. Since in each step the model takes as input a character and outputs a prediction for the next character in the sequence, both $x_t$ and $o_t$ are 65-dimensional vectors, i.e., $x_t, o_t \in \mathbb{R}^{65}$. We can choose any dimension for the hidden state $h_t$; in this case, we will use $h_t \in \mathbb{R}^{100}$. With this setup, the dimensions of $U$, $W$, and $V$ are $100 \times 65$, $100 \times 100$, and $65 \times 100$, respectively.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For a vector $\mathbf{x}$, we have:</p>
$$
\text{softmax}(\mathbf{x})_i = \frac{e^{\mathbf{x}_i}}{\sum_j e^{\mathbf{x}_j}}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Warning: not numerically stable</span>
<span class="k">def</span> <span class="nf">softmax_unstable</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">softmax_unstable</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python2.7/site-packages/autograd/core.py:134: RuntimeWarning: overflow encountered in exp
  result = self.fun(*argvals, **kwargs)
/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in divide
  app.launch_new_instance()
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[4]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([  0.,   0.,  nan])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Numerically stable version</span>
<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">exponential</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">exponential</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exponential</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">softmax</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[6]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([ 0.,  0.,  1.])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">log_softmax</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1000</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[8]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([ -1.38155106e+01,  -1.38155106e+01,   9.99999500e-07])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">initialize_params</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;U&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="s1">&#39;W&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="s1">&#39;V&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="s1">&#39;b_h&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">),</span>
        <span class="s1">&#39;b_o&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">params</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># test_params = initialize_params(2, 3, 2)</span>

<span class="c1"># for param in test_params:</span>
<span class="c1">#     print(&quot;{} = \n{}\n&quot;.format(param, test_params[param]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">initialize_hidden</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h_prev</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;U&#39;</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">],</span> <span class="n">h_prev</span><span class="p">)</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;b_h&#39;</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;V&#39;</span><span class="p">],</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;b_o&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">h</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Negative log-likelihood loss. Useful for training a classification problem with n classes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">output</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">target_seq</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">initialize_hidden</span><span class="p">(</span><span class="n">opts</span><span class="p">[</span><span class="s1">&#39;hidden_size&#39;</span><span class="p">])</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)):</span>
        <span class="c1"># output, hidden = model(params, input_seq[i], hidden)</span>
        <span class="c1"># loss += criterion(output, target_seq[i])</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">input_seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;U&#39;</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;b_h&#39;</span><span class="p">])</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;V&#39;</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;b_o&#39;</span><span class="p">])</span>
        
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_seq</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">loss_grad</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>def sgd(grad, init_params, callback=None, num_iters=200, step_size=0.1, mass=0.9):
    """Stochastic gradient descent with momentum.
    grad() must have signature grad(x, i), where i is the iteration number."""</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">initial</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">initialize_hidden</span><span class="p">(</span><span class="n">opts</span><span class="p">[</span><span class="s1">&#39;hidden_size&#39;</span><span class="p">])</span>
    <span class="n">current_char</span> <span class="o">=</span> <span class="n">initial</span>
    <span class="n">final_string</span> <span class="o">=</span> <span class="n">initial</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">create_one_hot</span><span class="p">(</span><span class="n">char_to_index</span><span class="p">[</span><span class="n">current_char</span><span class="p">],</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;input_size&#39;</span><span class="p">])</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        
        <span class="n">p</span> <span class="o">=</span> <span class="n">output</span>
        <span class="n">current_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
        <span class="n">current_char</span> <span class="o">=</span> <span class="n">index_to_char</span><span class="p">[</span><span class="n">current_index</span><span class="p">]</span>
        <span class="n">final_string</span> <span class="o">+=</span> <span class="n">current_char</span>
    
    <span class="k">return</span> <span class="n">final_string</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">create_one_hot</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
    <span class="n">vec</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">vec</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">data_length</span> <span class="o">/</span> <span class="n">sequence_length</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[42]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>22307</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Use non-overlapping 25-character chunks for training</span>
<span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">print_every</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">evaluate_every</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-2</span>

<span class="n">opts</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;input_size&#39;</span><span class="p">:</span> <span class="n">vocab_size</span><span class="p">,</span>
    <span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">&#39;output_size&#39;</span><span class="p">:</span> <span class="n">vocab_size</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">initialize_params</span><span class="p">(</span><span class="n">opts</span><span class="p">[</span><span class="s1">&#39;input_size&#39;</span><span class="p">],</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;hidden_size&#39;</span><span class="p">],</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;output_size&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># i = 0</span>
    <span class="c1"># while i * sequence_length + 1 &lt; 10000:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_length</span> <span class="o">/</span> <span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">sequence_length</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">sequence_length</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">chunk</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>

        <span class="n">input_chars</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">target_chars</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="n">input_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_index</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">input_chars</span><span class="p">]</span>
        <span class="n">target_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_index</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">target_chars</span><span class="p">]</span>
        
        <span class="n">input_seq_one_hot</span> <span class="o">=</span> <span class="p">[</span><span class="n">create_one_hot</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">input_seq</span><span class="p">]</span>
        
        <span class="n">example_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">input_seq_one_hot</span><span class="p">,</span> <span class="n">target_seq</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
        
        <span class="n">grad_params</span> <span class="o">=</span> <span class="n">loss_grad</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">input_seq_one_hot</span><span class="p">,</span> <span class="n">target_seq</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">grad_params</span><span class="p">[</span><span class="n">param</span><span class="p">],</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
            <span class="n">params</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">gradient</span>
        
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LOSS = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">example_loss</span><span class="p">))</span>
            <span class="c1"># print(grad_params)</span>
        
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">evaluate_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sampled_string</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="n">opts</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">sampled_string</span><span class="p">)</span>
        
        <span class="c1"># i += 1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>LOSS = 208.718692942
apoe;NwlIRZzjb3:UXbQ?Pf3aBq:VoHoC iqcElsCuz;Db&amp;jb;EFjiiPjK,LOWtfHihlmfN
&#39;FEqPct uyriA
nxR.&amp;dNEh-tVIIc
LOSS = 149.711116906
ayoauy  n oeraems ts UlasaeunirIlw .wphtFhtbr . 
anetynoh eemes xry  yer O
, yel&#39;trmTr t n alhrtp Qnh
LOSS = 145.986176536
a,re u uecnE o y
 noea?Te rt wosh iZ ?irSuBe: nnB,ib
ser sSTtIbNSeynueha
,uy cotn mo
 ssSYe th d thrt
LOSS = 137.139640333
ad fm
pnic wanhcgnls
ln un nioa ace ram p yege, ie Roninole Cia nIle: uoun ho yed the s lor no
 $wiod
LOSS = 133.168522424
alt Ww y lor.ENoreUedeqten Gpv ced muy irdeeeit, was fotelr. liiterra.

VPQZeil. yine oallaea

hire p
LOSS = 114.793422502
at oy mon3 t woun goin, tour no ouge aumd couie, wit une, Luar! por bonosy ve sikdipus tou&#39; the simar
LOSS = 124.662118004
amr cadiw,erethary he soadeigc cilei.

MRI&amp;germ, nntham.

WIUA
jsRoll.

ISAU3urer af aimouv ar augaks
LOSS = 101.45352779
as tous.
The pal touso mit atoitheatt the noutt:,
Thoul hor or Gas t, fivve het hho forts moe I cule 
LOSS = 99.5976097895
apyerenga terighibn bar hek&#39; n bsekhe the pout yhua.

MqNCCN:
ICU:UC,

MMVBUS:,
Won bos houominue: of
LOSS = 123.162025095
af tos wull:
Shic in the, in gxPq

VMEC?EENqot twe s st eo dorr t se he, ees
Home

Min:
T;A he t py g
LOSS = 120.606505898
at outh tous
SeRice&#39;, ofe she ino pa tig aler,
MMMTINNIUINI:I:
A&#39;CAvur
MeOC LCIUMNI: in M
we cor whar
LOSS = 112.87250068
ally t en ir te-domd, bourse pofent ry is is o&amp;mereles erpowid bery at or oll3 the tom poind&#39;tt epon 
LOSS = 134.518660817
a musther
Cher,; and Fo, thaveus weit  okd pestherdourI neus titirmeron coot, Cwive. Yeouldelgn!
Hent
LOSS = 121.666809607
aft hich! honbert, hib doun pussrut he; wre.
EfThon
zeanetesstonat ofroureksko&#39;t hoime eoertind arsth
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-43-83aab31427ef&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>         example_loss <span class="ansi-blue-fg">=</span> loss<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> input_seq_one_hot<span class="ansi-blue-fg">,</span> target_seq<span class="ansi-blue-fg">,</span> opts<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span> 
<span class="ansi-green-fg">---&gt; 34</span><span class="ansi-red-fg">         </span>grad_params <span class="ansi-blue-fg">=</span> loss_grad<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> input_seq_one_hot<span class="ansi-blue-fg">,</span> target_seq<span class="ansi-blue-fg">,</span> opts<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     35</span>         <span class="ansi-green-fg">for</span> param <span class="ansi-green-fg">in</span> params<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     36</span>             gradient <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>clip<span class="ansi-blue-fg">(</span>grad_params<span class="ansi-blue-fg">[</span>param<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">5</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">5</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/autograd/core.pyc</span> in <span class="ansi-cyan-fg">gradfun</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span>     <span class="ansi-blue-fg">@</span>attach_name_and_doc<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span> argnum<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;Gradient&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     21</span>     <span class="ansi-green-fg">def</span> gradfun<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 22</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> backward_pass<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>forward_pass<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span>args<span class="ansi-blue-fg">,</span>kwargs<span class="ansi-blue-fg">,</span>argnum<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span>     <span class="ansi-green-fg">return</span> gradfun
<span class="ansi-green-intense-fg ansi-bold">     24</span> 

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/autograd/core.pyc</span> in <span class="ansi-cyan-fg">backward_pass</span><span class="ansi-blue-fg">(start_node, end_node, tape, preserve_tape)</span>
<span class="ansi-green-intense-fg ansi-bold">     57</span>                 <span class="ansi-blue-fg">&#34;Types are {0} and {1}&#34;</span><span class="ansi-blue-fg">.</span>format<span class="ansi-blue-fg">(</span>type<span class="ansi-blue-fg">(</span>new_node<span class="ansi-blue-fg">(</span>getval<span class="ansi-blue-fg">(</span>cur_outgrad<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> node<span class="ansi-blue-fg">.</span>node_type<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     58</span>             <span class="ansi-green-fg">for</span> gradfun<span class="ansi-blue-fg">,</span> parent <span class="ansi-green-fg">in</span> node<span class="ansi-blue-fg">.</span>parent_grad_ops<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 59</span><span class="ansi-red-fg">                 </span>og <span class="ansi-blue-fg">=</span> cast_to_node_type<span class="ansi-blue-fg">(</span>gradfun<span class="ansi-blue-fg">(</span>cur_outgrad<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> parent<span class="ansi-blue-fg">.</span>node_type<span class="ansi-blue-fg">,</span> parent<span class="ansi-blue-fg">.</span>node_value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     60</span>                 parent<span class="ansi-blue-fg">.</span>outgrads<span class="ansi-blue-fg">.</span>append<span class="ansi-blue-fg">(</span>og<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     61</span> 

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/autograd/numpy/numpy_grads.pyc</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(g)</span>
<span class="ansi-green-intense-fg ansi-bold">    535</span>             <span class="ansi-green-fg">return</span> result
<span class="ansi-green-intense-fg ansi-bold">    536</span>     <span class="ansi-green-fg">elif</span> isarray<span class="ansi-blue-fg">(</span>ans<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 537</span><span class="ansi-red-fg">         </span>new_fun <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">lambda</span> g <span class="ansi-blue-fg">:</span> anp<span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>gradfun<span class="ansi-blue-fg">(</span>g<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    538</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    539</span>         <span class="ansi-green-fg">return</span> gradfun

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/autograd/numpy/numpy_grads.pyc</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(g)</span>
<span class="ansi-green-intense-fg ansi-bold">     74</span> anp<span class="ansi-blue-fg">.</span>subtract<span class="ansi-blue-fg">.</span>defgrad<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> ans<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y <span class="ansi-blue-fg">:</span> unbroadcast<span class="ansi-blue-fg">(</span>ans<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> op<span class="ansi-blue-fg">.</span>neg<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> argnum<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     75</span> anp<span class="ansi-blue-fg">.</span>divide<span class="ansi-blue-fg">.</span>defgrad<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> ans<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y <span class="ansi-blue-fg">:</span> unbroadcast<span class="ansi-blue-fg">(</span>ans<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">lambda</span> g <span class="ansi-blue-fg">:</span>   g <span class="ansi-blue-fg">/</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 76</span><span class="ansi-red-fg"> </span>anp<span class="ansi-blue-fg">.</span>divide<span class="ansi-blue-fg">.</span>defgrad<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> ans<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y <span class="ansi-blue-fg">:</span> unbroadcast<span class="ansi-blue-fg">(</span>ans<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">lambda</span> g <span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">-</span> g <span class="ansi-blue-fg">*</span> x <span class="ansi-blue-fg">/</span> y<span class="ansi-blue-fg">**</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> argnum<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     77</span> anp<span class="ansi-blue-fg">.</span>power<span class="ansi-blue-fg">.</span>defgrad<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> ans<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y <span class="ansi-blue-fg">:</span> unbroadcast<span class="ansi-blue-fg">(</span>ans<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">lambda</span> g <span class="ansi-blue-fg">:</span> g <span class="ansi-blue-fg">*</span> y <span class="ansi-blue-fg">*</span> x <span class="ansi-blue-fg">**</span> <span class="ansi-blue-fg">(</span>anp<span class="ansi-blue-fg">.</span>where<span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">,</span> y <span class="ansi-blue-fg">-</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1.</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     78</span> anp.power.defgrad(

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/autograd/numpy/numpy_extra.pyc</span> in <span class="ansi-cyan-fg">__pow__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-intense-fg ansi-bold">     63</span>     <span class="ansi-green-fg">def</span> __sub__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span> anp<span class="ansi-blue-fg">.</span>subtract<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     64</span>     <span class="ansi-green-fg">def</span> __mul__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span> anp<span class="ansi-blue-fg">.</span>multiply<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 65</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">def</span> __pow__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span> anp<span class="ansi-blue-fg">.</span>power   <span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     66</span>     <span class="ansi-green-fg">def</span> __div__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span> anp<span class="ansi-blue-fg">.</span>divide<span class="ansi-blue-fg">(</span>  self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     67</span>     <span class="ansi-green-fg">def</span> __mod__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span> anp<span class="ansi-blue-fg">.</span>mod<span class="ansi-blue-fg">(</span>     self<span class="ansi-blue-fg">,</span> other<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/autograd/core.pyc</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    132</span>                         tapes<span class="ansi-blue-fg">.</span>add<span class="ansi-blue-fg">(</span>tape<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    133</span> 
<span class="ansi-green-fg">--&gt; 134</span><span class="ansi-red-fg">         </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>fun<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>argvals<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>         <span class="ansi-green-fg">if</span> result <span class="ansi-green-fg">is</span> NotImplemented<span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span> result
<span class="ansi-green-intense-fg ansi-bold">    136</span>         <span class="ansi-green-fg">if</span> ops<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)</span>
<span class="sd">BSD License</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># data I/O</span>
<span class="n">data</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/shakespeare.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span> <span class="c1"># should be simple plain text file</span>
<span class="n">chars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">data_size</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
<span class="nb">print</span> <span class="s1">&#39;data has </span><span class="si">%d</span><span class="s1"> characters, </span><span class="si">%d</span><span class="s1"> unique.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">data_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">char_to_ix</span> <span class="o">=</span> <span class="p">{</span> <span class="n">ch</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>
<span class="n">ix_to_char</span> <span class="o">=</span> <span class="p">{</span> <span class="n">i</span><span class="p">:</span><span class="n">ch</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>

<span class="c1"># hyperparameters</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># size of hidden layer of neurons</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">50</span> <span class="c1"># number of steps to unroll the RNN for</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-2</span>

<span class="c1"># model parameters</span>
<span class="n">Wxh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span> <span class="c1"># input to hidden</span>
<span class="n">Whh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span> <span class="c1"># hidden to hidden</span>
<span class="n">Why</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span> <span class="c1"># hidden to output</span>
<span class="n">bh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># hidden bias</span>
<span class="n">by</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># output bias</span>

<span class="k">def</span> <span class="nf">lossFun</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">hprev</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    inputs,targets are both list of integers.</span>
<span class="sd">    hprev is Hx1 array of initial hidden state</span>
<span class="sd">    returns the loss, gradients on model parameters, and last hidden state</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">ps</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{}</span>
    <span class="n">hs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hprev</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># forward pass</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
        <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># encode in 1-of-k representation</span>
        <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="n">bh</span><span class="p">)</span> <span class="c1"># hidden state</span>
        <span class="n">ys</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">+</span> <span class="n">by</span> <span class="c1"># unnormalized log probabilities for next chars</span>
        <span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="c1"># probabilities for next chars</span>
        
        <span class="n">loss</span> <span class="o">+=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">targets</span><span class="p">[</span><span class="n">t</span><span class="p">],</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># softmax (cross-entropy loss)</span>
    
    
    <span class="c1"># backward pass: compute gradients going backwards</span>
    <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Wxh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Whh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Why</span><span class="p">)</span>
    <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">bh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
    <span class="n">dhnext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))):</span>
        <span class="n">dy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
        <span class="n">dy</span><span class="p">[</span><span class="n">targets</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">-=</span> <span class="mi">1</span> <span class="c1"># backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here</span>
        <span class="n">dWhy</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dby</span> <span class="o">+=</span> <span class="n">dy</span>
        <span class="n">dh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">+</span> <span class="n">dhnext</span> <span class="c1"># backprop into h</span>
        <span class="n">dhraw</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">*</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">*</span> <span class="n">dh</span> <span class="c1"># backprop through tanh nonlinearity</span>
        <span class="n">dbh</span> <span class="o">+=</span> <span class="n">dhraw</span>
        <span class="n">dWxh</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dhraw</span><span class="p">,</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dWhh</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dhraw</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dhnext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dhraw</span><span class="p">)</span>
    <span class="c1"># for dparam in [dWxh, dWhh, dWhy, dbh, dby]:</span>
    <span class="c1">#  np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients</span>
    
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">seed_ix</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    sample a sequence of integers from the model </span>
<span class="sd">    h is memory state, seed_ix is seed letter for first time step</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span><span class="p">[</span><span class="n">seed_ix</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ixes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">bh</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">by</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">ixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ixes</span>

<span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
<span class="n">mWxh</span><span class="p">,</span> <span class="n">mWhh</span><span class="p">,</span> <span class="n">mWhy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Wxh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Whh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Why</span><span class="p">)</span>
<span class="n">mbh</span><span class="p">,</span> <span class="n">mby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">bh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">by</span><span class="p">)</span> <span class="c1"># memory variables for Adagrad</span>
<span class="n">smooth_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">vocab_size</span><span class="p">)</span><span class="o">*</span><span class="n">seq_length</span> <span class="c1"># loss at iteration 0</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="c1"># prepare inputs (we&#39;re sweeping from left to right in steps seq_length long)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">hprev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># reset RNN memory</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># go from start of data</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_ix</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="p">:</span><span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="p">]]</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_ix</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>

    <span class="c1"># sample from the model now and then</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sample_ix</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">hprev</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">200</span><span class="p">)</span>
        <span class="n">txt</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ix_to_char</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="k">for</span> <span class="n">ix</span> <span class="ow">in</span> <span class="n">sample_ix</span><span class="p">)</span>
        <span class="nb">print</span> <span class="s1">&#39;----</span><span class="se">\n</span><span class="s1"> </span><span class="si">%s</span><span class="s1"> </span><span class="se">\n</span><span class="s1">----&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="p">)</span>

    <span class="n">hprev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># reset RNN memory</span>
    <span class="c1"># forward seq_length characters through the net and fetch gradient</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">,</span> <span class="n">hprev</span> <span class="o">=</span> <span class="n">lossFun</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">hprev</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="nb">print</span> <span class="s1">&#39;iter </span><span class="si">%d</span><span class="s1">, loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span> <span class="c1"># print progress</span>
  
    <span class="c1"># perform parameter update with Adagrad</span>
    <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">dparam</span><span class="p">,</span> <span class="n">mem</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">Whh</span><span class="p">,</span> <span class="n">Why</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">by</span><span class="p">],</span> 
                                  <span class="p">[</span><span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">],</span> 
                                  <span class="p">[</span><span class="n">mWxh</span><span class="p">,</span> <span class="n">mWhh</span><span class="p">,</span> <span class="n">mWhy</span><span class="p">,</span> <span class="n">mbh</span><span class="p">,</span> <span class="n">mby</span><span class="p">]):</span>
        <span class="c1"># mem += dparam * dparam</span>
        <span class="c1"># param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update</span>
        <span class="n">param</span> <span class="o">+=</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dparam</span>

    <span class="n">p</span> <span class="o">+=</span> <span class="n">seq_length</span> <span class="c1"># move data pointer</span>
    <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># iteration counter </span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>data has 1115394 characters, 65 unique.
----
 QrBwOo.&amp;YymnHF yQrH-gq:wGdIl X
PYl$;DUgVnqXlJx$hNY&amp;ika,:fA$QzsuXcHTCm?BYxo&amp;V.okilFUqOZXE$LDOx$&amp;NJrvvJCUAEKjX;Ethj$t
dOhiDpMtmqv.AgPV.fnJBeIAopCGfp$lbt3aBQUozwqfbibsSBW.hMC?fmBjh-LodcYXYs?.P$Rn?&amp;3g,-$B 
----
iter 0, loss: 208.719587
----
 afisetemQi o.teelldysel ye$i faea3ooMlaetglehi vie, rsiya l
yoayunda,enn&#39;esbS  tfmi tsplihx SL:eUwrecvi enoszsnvocezenhaiNel nhvtek eye b?WpiyX  mtmeracene nml ietestIo
ttyhlis tbYa
k t 
m etrhlbtnaO  
----
iter 100, loss: 149.686243
----
 lm,j ig y
Tigithngrreh dfhuVt
 qeaet te wddrhd;oi?edkiMt&#39; woE t,trarii.d 
erhkM iistr . ttbrn!saegke nnihs riadoW hiwo &amp;hwo
tGb.snleho r&#39; pN,r e
 :t, ty rheuzgiuo,t thei r,nsmeieyd&#39;hononyn;  
to oej t 
----
iter 200, loss: 146.590819
----
  itl acy hiwe mamgoue wodat Wrus ah. os lhoiuu&#39;. wos omen semte nod ,r t uinceinneoylrUenomee wh Nhe
b:aakrnwoIt lanueew horSyda,os mUs fongtwhee Kans hewstyeaad
 he the oalsweisy dhet sglsoncpsw heuh 
----
iter 300, loss: 136.269761
----
 y:r.rawNen
dye the themi?.nn D;nde,ile pe,thoublind Ior l, fs buuCesune, hemesUo:IL
ZcwamencilenllI
VoZceri t, the oheg
vemRG;he.d jothesfd son,Mrs in ghel , mo .eTere nod tolnsiIhs oo, got lounCume c 
----
iter 400, loss: 134.828539
----
 de yh, thenserndgeldecoe gthe siisn i&#39;:isisrt
Ao shepweid lerkere ser. colf niemit nis yulot bWou: tiwec

Githrar yuT torag &#39;, tol:
Thunvs finildcooue hatl s womes uuc naR. spreor toos aceur.:
XET.R n 
----
iter 500, loss: 115.537298
----
 pet de bereile alm
Wha
ho&#39;d weur thovgme he fe ornder:

MpoFlt thiu hirM fula:disere: shalls b ala hat goulst rod spy:rodet&#39;
the milt. turinNs sher t theme houvz
Sereje:,sn are cede, war st
SAmO alete 
----
iter 600, loss: 124.320122
----
 han,

Ver srte cotd Im.
Bnint, st weelerwI!o,
Rherg
Pf thonl d rals: tsfche n3sarit, yor;
A&#39;tgast helt thunt
Tyiele thestrans ghet wom ron, wamdub hets rad.
U?est; nand I mirns ham? bisin uronct Coh?  
----
iter 700, loss: 102.191199
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-22-2fe01ebf7e56&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">    105</span>     hprev <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>zeros<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span>hidden_size<span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># reset RNN memory</span>
<span class="ansi-green-intense-fg ansi-bold">    106</span>     <span class="ansi-red-fg"># forward seq_length characters through the net and fetch gradient</span>
<span class="ansi-green-fg">--&gt; 107</span><span class="ansi-red-fg">     </span>loss<span class="ansi-blue-fg">,</span> dWxh<span class="ansi-blue-fg">,</span> dWhh<span class="ansi-blue-fg">,</span> dWhy<span class="ansi-blue-fg">,</span> dbh<span class="ansi-blue-fg">,</span> dby<span class="ansi-blue-fg">,</span> hprev <span class="ansi-blue-fg">=</span> lossFun<span class="ansi-blue-fg">(</span>inputs<span class="ansi-blue-fg">,</span> targets<span class="ansi-blue-fg">,</span> hprev<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    108</span>     <span class="ansi-green-fg">if</span> n <span class="ansi-blue-fg">%</span> <span class="ansi-cyan-fg">100</span> <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">print</span> <span class="ansi-blue-fg">&#39;iter %d, loss: %f&#39;</span> <span class="ansi-blue-fg">%</span> <span class="ansi-blue-fg">(</span>n<span class="ansi-blue-fg">,</span> loss<span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># print progress</span>
<span class="ansi-green-intense-fg ansi-bold">    109</span> 

<span class="ansi-green-fg">&lt;ipython-input-22-2fe01ebf7e56&gt;</span> in <span class="ansi-cyan-fg">lossFun</span><span class="ansi-blue-fg">(inputs, targets, hprev)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span>         hs<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>tanh<span class="ansi-blue-fg">(</span>np<span class="ansi-blue-fg">.</span>dot<span class="ansi-blue-fg">(</span>Wxh<span class="ansi-blue-fg">,</span> xs<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> np<span class="ansi-blue-fg">.</span>dot<span class="ansi-blue-fg">(</span>Whh<span class="ansi-blue-fg">,</span> hs<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> bh<span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># hidden state</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span>         ys<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>dot<span class="ansi-blue-fg">(</span>Why<span class="ansi-blue-fg">,</span> hs<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> by <span class="ansi-red-fg"># unnormalized log probabilities for next chars</span>
<span class="ansi-green-fg">---&gt; 44</span><span class="ansi-red-fg">         </span>ps<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>exp<span class="ansi-blue-fg">(</span>ys<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">/</span> np<span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>np<span class="ansi-blue-fg">.</span>exp<span class="ansi-blue-fg">(</span>ys<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># probabilities for next chars</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span> 
<span class="ansi-green-intense-fg ansi-bold">     46</span>         loss <span class="ansi-blue-fg">+=</span> <span class="ansi-blue-fg">-</span>np<span class="ansi-blue-fg">.</span>log<span class="ansi-blue-fg">(</span>ps<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">[</span>targets<span class="ansi-blue-fg">[</span>t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># softmax (cross-entropy loss)</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Long-Short-Term-Memory-Networks-(LSTMs)">Long Short-Term Memory Networks (LSTMs)<a class="anchor-link" href="#Long-Short-Term-Memory-Networks-(LSTMs)">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The update of an LSTM is given by the following equations:</p>
$$
i_t = \sigma(U_i x_t + W_i h_{t-1} + b_i)
$$$$
f_t = \sigma(U_f x_t + W_f h_{t-1} + b_f)
$$$$
o_t = \sigma(U_o x_t + W_o h_{t-1} + b_o)
$$$$
\tilde{C}_t = \tanh(U_C x_t + W_C h_{t-1} + b_C)
$$$$
C_t = i_t * \tilde{C}_t + f_t * C_{t-1}
$$$$
h_t = o_t * \tanh(C_t)
$$
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Gated-Recurrent-Units-(GRU)">Gated Recurrent Units (GRU)<a class="anchor-link" href="#Gated-Recurrent-Units-(GRU)">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 


    </div>
  </div>

  </div>


  
    <footer class="footer hidden-print">
      <div class="container">
        <div class="col-md-4">
          <p>
            This website does not host notebooks, it only renders notebooks
            available on other websites.
          </p>
        </div>

        <div class="col-md-4">
          <p>
            Delivered by <a href="https://www.fastly.com/">Fastly</a>,
            Rendered by <a href="https://ovhcloud.com">OVHcloud</a>
          </p>
          <p>
            nbviewer GitHub <a href="https://github.com/jupyter/nbviewer">repository</a>.
          </p>
        </div>

        <div class="col-md-4">
          
  
            
              <p>
                nbviewer version:
                <a href="https://github.com/jupyter/nbviewer/commit/d25d3c39c10d5f6b9891eba2503f30689c1aae28">
                  d25d3c3
                </a>
              </p>
            
          
  
  <p>
    nbconvert version: <a href="https://github.com/jupyter/nbconvert/releases/tag/5.6.1">
      5.6.1
    </a>
  </p>
  

          
  
  
  <p>
    Rendered
    <span class='date' data-date='Thu, 19 May 2022 02:16:19 UTC' title='Thu, 19 May 2022 02:16:19 UTC'>(Thu, 19 May 2022 02:16:19 UTC)</span>
  </p>
  

        </div>
      </div>
    </footer>
  

  <script src="/static/components/bootstrap/js/bootstrap.min.js"></script>
  <script src="/static/components/headroom.js/dist/headroom.min.js"></script>
  <script src="/static/components/headroom.js/dist/jQuery.headroom.min.js"></script>

  
  
  <script>
    $(function(){ $("#menubar").headroom({
      tolerance: 5,
      offset: 205,
      classes: {
        initial: "animated",
        pinned: "slideInDown",
        unpinned: "slideOutUp"
      }
    })});
  </script>


  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-52617120-5', 'auto',
       {'storage': 'none'});
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  
  <script>
    require({
        paths: {
          moment: "/static/components/moment/min/moment.min.js"
        }
      }, ["moment"], function(moment){
      var date = $("footer .date"),
        m = moment(new Date(date.data('date'))),
        update = function(){ date.text(m.fromNow()); };
      setInterval(update, 61*1000);
      update();
      var w = $(window).scroll(function(event){
        $("body").toggleClass("scrolled", w.scrollTop() > 0);
      });
    });
  </script>

  <!--NEW RELIC Stop Perf Measurement-->
  
  <!--NEW RELIC End-->
</body>
</html>